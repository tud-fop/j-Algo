\newtheorem{alg}{Algorithmus}

\chapter{\label{appendix_avl_A}Einleitung zu Datenstrukturen}
{\bfseries Anmerkung:} Die Kapitel \ref{appendix_avl_A}, \ref{appendix_avl_B} und \ref{appendix_avl_C} dieses Anhangs wurden erstellt von:\\
Jean Christoph Jung

Eine h�ufige Anwendung auf gro�en Datenmengen ist das Suchen: Das Wiederfinden eines bestimmten Elements oder bestimmter Informationen aus einer gro�en Menge fr�her abgelegter Daten. Um die Suche zu vereinfachen, werden den (m�glicherweise sehr komplexen) gro�en Datens�tzen eineindeutige Suchschl�ssel (Keys) zugeordnet. Der Vergleich zweier solcher Schl�ssel ist in der Regel viel schneller als der Vergleich zweier Datens�tze. Wegen der Schl�sselzuordnung reicht es aus, alle vorkommenden Algorithmen nur auf den Schl�sseln zu betrachten; in Wirklichkeit verweisen erst die Schl�ssel auf die Datens�tze.\\
Eine grundlegende Idee ist nun, die Daten in Form einer Liste oder eines Feldes abzulegen. Diese Datenstruktur ist h�chst einfach. Jedoch ist der Aufwand f�r das Suchen relativ hoch, n�mlich $O(n)$. Genauer gesagt ben�tigt man f�r eine erfolglose Suche $n$ Vergleiche (bei $n$ Elementen in der Datenstruktur), denn man muss jedes Element �berpr�fen, und f�r eine erfolgreiche Suche durchschnittlich $(n+1)/2$ Vergleiche durchf�hren, da nach jedem Element mit der gleichen Wahrscheinlichkeit gesucht wird.\\
Eine Verbesserung dieses Verfahrens w�re, die Daten sortiert abzulegen, was zu einer bin�ren Suche f�hrt. Die Suche hat jetzt nur noch Komplexit�t $O(\log_2{n})$, da bei jedem Suchschritt das Feld halbiert wird. Der Nachteil ist, dass durch die Sortierung das Einf�gen erschwert wird, da unter Umst�nden viele Datens�tze bewegt werden m�ssen. Das Verfahren sollte also nur angewandt werden, wenn sehr wenige oder gar keine Einf�geoperationen ausgef�hrt werden m�ssen. Dann k�nnen die Daten anfangs mit einem schnellen Verfahren sortiert werden und m�ssen danach nicht mehr ver�ndert werden.\\
Eine weitere Datenstruktur, die der Suchb�ume, wollen wir hier vorstellen.

\chapter{\label{appendix_avl_B}Suchb�ume}
Suchb�ume sind bin�re B�ume (jeder Knoten hat h�chstens 2 Kinder) mit der Eigenschaft:\\
F�r jeden Knoten gilt: alle Schl�ssel im rechten Teilbaum sind gr��er als der eigene Schl�ssel und alle Schl�ssel im linken Teilbaum sind kleiner. Diese Eigenschaft wird hier immer Suchbaumeigenschaft genannt.

\centerpic{avl/bsp_suchbaum}{4.5}{Ein Beispiel f�r einen Suchbaum} 

An dieser Stelle noch eine Bemerkung zu den Schl�sseln: Die Schl�ssel k�nnen Elemente einer beliebigen Menge sein, unter der Bedingung, dass auf dieser Menge eine Ordnungsrelation definiert ist. Die Ordnungsrelation wird offensichtlich f�r die Suchbaumeigenschaft ben�tigt, da dort die Begriffe "`kleiner"' und "`gr��er"' vorkommen. Eine h�ufig verwendete Menge sind die nat�rlichen Zahlen mit ihrer normalen Ordnungsrelation $\leq$. Alle Operationen auf Suchb�umen kann man sich also anhand der nat�rlichen Zahlen vorstellen.\\
Aus der Suchbaumeigenschaft kann man sich leicht rekursive Algorithmen f�r das Einf�gen und Suchen in einem Suchbaum herleiten:

\begin{alg} \label{search}
	(Suchen eines Schl�ssels $s$ in einem Suchbaum)
	\begin{enumerate}
		\item Falls Teilbaum leer, dann Schl�ssel nicht im Baum vorhanden
		\item Falls $s$ gleich dem Schl�ssel des aktuellen Knoten, dann Suche erfolgreich.
		\item Falls $s$ gr��er als Schl�ssel des aktuellen Knotens, dann suche (rekursiv) $s$ im rechten Teilbaum.
		\item Falls $s$ kleiner als Schl�ssel des aktuellen Knotens, dann suche (rekursiv) $s$ im linken Teilbaum.
	\end {enumerate}
\end{alg}

\newpage
\begin{alg} \label{insert}
	(Einf�gen eines Schl�ssels $s$ in einen Suchbaum)
	\begin {enumerate}
		\item Falls Teilbaum leer, dann neuen Schl�ssel hier einf�gen.
		\item Falls $s$ gleich dem Schl�ssel des aktuellen Knotens, dann Schl�ssel bereits vorhanden, Einf�gen nicht n�tig.
		\item Falls $s$ gr��er als Schl�ssel des aktuellen Knotens, dann f�ge (rekursiv) $s$ in den rechten Teilbaum ein.
		\item Falls $s$ kleiner als Schl�ssel des aktuellen Knotens, dann f�ge (rekursiv) $s$ in den linken Teilbaum ein.
	\end {enumerate}
\end{alg}

Mit Algorithmus \ref{insert} ergibt sich folgende Eigenschaft der Struktur von Suchb�umen: im Gegensatz zur sortierten Liste h�ngt die Struktur eines Baumes davon ab, in welcher Reihenfolge die Elemente eingef�gt werden. So erh�lt man verschiedene B�ume, wenn man $1, 2, 3, 4$ in dieser Reihenfolge und in der Reihenfolge $3, 2, 4, 1$ einf�gt.

\centerpic{avl/12345}{4}{Unterschiedliche Suchb�ume bei unterschiedlicher Einf�gereihenfolge} 

Im ersten Fall erh�lt man einen Suchbaum, der zur linearen Liste entartet ist. Das ist nicht nur in dieser speziellen Reihenfolge so, es gibt viele M�glichkeiten einen entarteten Baum zu erzeugen. Der Algorithmus hat also zwei Nachteile: zum einen kann der Suchaufwand linear zur Anzahl der Knoten im Baum sein, was keine Verbesserung zur linearen Liste darstellt; zum anderen h�ngt die G�te des Verfahrens von der Eingabefolge ab. Der Vorteil von Suchb�umen wird klar, wenn man einen "`vollen"' Baum betrachtet, d.h. alle Pfade zu Bl�ttern haben dieselbe L�nge. Dann hat sowohl das Suchen (unabh�ngig davon, ob der Schl�ssel im Baum vorhanden ist) als auch das Einf�gen eine Komplexit�t von $O(\log{n})$.

\centerpic{avl/vollerbaum}{5}{Ein Beispiel f�r einen vollen Baum}
\medskip
Es gibt einige Algorithmen, bei denen der Einf�gealgorithmus so modifiziert ist, dass die entarteten F�lle vermieden werden und immer nahezu volle B�ume entstehen. Einen davon, den Algorithmus nach Adelson-Velskij und Landis (AVL), werden wir sp�ter betrachten.

Doch zun�chst wollen wir noch eine weitere wichtige Operation auf Suchb�umen untersuchen: das L�schen. Leider ist es nicht ganz so einfach wie Suche und Einf�gen.\\
Zuerst muss der zu l�schende Schl�ssel gesucht werden. Ist der betreffende Knoten ein Blatt, kann er einfach entfernt werden. Hat der zu l�schende Knoten nur ein Kind, kann er durch dieses ersetzt werden. Der schwierige Fall ist, wenn er zwei Kinder hat. Damit die Suchbaumeigenschaft erhalten bleibt, muss man ihn durch den n�chst gr��eren Schl�ssel ersetzen. Der n�chst gr��ere Schl�ssel befindet sich offensichtlich im rechten Teilbaum.

\centerpic{avl/remove}{5}{L�schen eines Knoten im Suchbaum}
\medskip
Nach dem Ersetzen bleibt die Suchbaumeigenschaft erhalten, weil alle Schl�ssel aus dem linken Teilbaum ohnehin kleiner sind als die aus dem rechten. Au�erdem sind auch alle Schl�ssel aus dem rechten Teilbaum gr��er, sonst w�re es nicht der n�chst gr��ere Schl�ssel gewesen. Aus diesen �berlegungen erh�lt man folgende verbale Beschreibung des L�schen-Algorithmus:

\newpage
\begin{alg} \label{delete}
	(L�schen eines Schl�ssels $s$ aus einem Suchbaum)
	\begin{enumerate}
		\item Suche s nach Algorithmus \ref{search}. Falls s nicht im Baum enthalten, terminiert der Algorithmus.
		\item \begin{enumerate}
			\item Ist der zu l�schende Knoten ein Blatt, dann entferne ihn einfach aus dem Baum.
			\item Hat der zu l�schende Knoten nur ein Kind, dann ersetze ihn durch dieses.
			\item Sonst suche den kleinsten Schl�ssel im rechten Teilbaum: Gehe zum rechten Kind und dann immer zum linken Teilbaum, solange dieser nicht leer ist. Ersetze den zu l�schenden Schl�ssel durch den des so gefundenen Knotens. Ersetze den gefundenen Knoten durch sein rechtes Kind.
			\end{enumerate}
	\end{enumerate}
\end{alg}

Man kann anstelle des n�chst gr��eren Schl�ssels genausogut den n�chstkleineren nehmen, der Algorithmus funktioniert trotzdem. Zur Komplexit�t ist zu sagen, dass der Algorithmus maximal $h$ Vergleiche macht, wobei $h$ die H�he des Baumes ist. Auch hier ist also die Komplexit�t abh�ngig von der Struktur des Baumes.

\chapter{\label{appendix_avl_C}AVL-B�ume}
AVL-B�ume (benannt nach Adelson-Velskij und Landis) sind spezielle Suchb�ume: In jedem Knoten unterscheiden sich die H�hen des linken Teilbaums und des rechten Teilbaums um h�chstens 1. Um diese Eigenschaft (AVL-Eigenschaft) abzusichern, wird f�r jeden Knoten ein Balancefaktor eingef�hrt. Der Balancefaktor ist die Differenz der H�hen des rechten Teilbaums und des linken Teilbaums. Also gilt f�r jeden AVL-Baum, dass alle Balancefaktoren aus $\{-1,0,1\}$ sind. B�ume mit AVL-Eigenschaft sind niemals als lineare Liste entartet (sofern sie denn mehr als 2 Knoten haben), sondern sind immer fast vollst�ndig. Zwischen der H�he $h$ eines Baumes und der Anzahl $n$ seiner Knoten besteht folgender Zusammenhang: $h\leq 2 \cdot \log_2{n}$. Das bedeutet, dass f�r das Suchen logarithmische Komplexit�t garantiert werden kann (das Suchen erfolgt gem�� Algorithmus \ref{search}).

\centerpic{avl/avlbsp}{5}{Ein Beispiel f�r einen AVL-Baum mit Balancen}
\medskip
Jetzt muss noch untersucht werden, wie gro� der zus�tzliche Aufwand beim Einf�gen ist, um die AVL-Eigenschaft zu wahren. In jedem Fall wird der neue Knoten als Blatt eingef�gt (nach demselben Algorithmus wie bei Suchb�umen). Dabei kann sich der Balancefaktor �ndern. Allerdings kann man sich leicht klarmachen, dass das nur entlang des Suchpfades passieren kann. Die Aktualisierung von Balancefaktoren erfolgt von der Einf�gestelle zur Wurzel. Hier der Algorithmus:

\newpage
\begin{alg} \label{avlinsert}
	(Algorithmus zum Einf�gen eines Elements x in einen AVL-Baum)
	\begin{enumerate}
		\item F�ge das neue Element x als direkten Nachfolger des Knotens n als Blatt ein, sodass die Suchbaumeigenschaft erf�llt bleibt. Aktualisiere n.balance.
		\item Setze n auf den Vorg�ngerknoten von n.
			\begin{enumerate}
				\item Falls x im linken Unterbaum von n eingef�gt wurde
					\begin{enumerate}
						\item wenn n.balance==1 dann n.balance=0 und gehe nach 3.
						\item wenn n.balance==0, dann n.balance=-1 und gehe nach 2.
						\item wenn n.balance==-1 und 
							\begin{itemize}
								\item wenn n.left.balance==-1, dann Rechts(n)-Rotation.
								\item wenn n.left.balance==1 dann Links(n.left)-Rechts(n)-Rotation.
							\end{itemize}
							Gehe zu 3.
					\end{enumerate}
				\item Falls x im rechten Unterbaum von n eingef�gt wurde
					\begin{enumerate}
						\item wenn n.balance==-1 dann n.balance=0 und gehe nach 3.
						\item wenn n.balance==0, dann n.balance=1 und gehe nach 2.
						\item wenn n.balance==1 und
							\begin{itemize}
								\item wenn n.left.balance==1, dann Links(n)-Rotation.
								\item wenn n.left.balance==-1 dann Rechts(n.left)-Links(n)-Rotation.
							\end{itemize}
							Gehe zu 3.
					\end{enumerate}
			\end{enumerate}
		\item Gehe zur�ck zur Wurzel.
	\end{enumerate}
\end{alg}

Zur Analyse dieses Algorithmus: Das reine Einf�gen erfolgt gem�� Einf�gen im Suchbaum (Algorithmus \ref{insert}), allerdings ist hier sichergestellt, dass sich die H�he logarithmisch zur Anzahl der Knoten verh�lt, d.h. auch der Aufwand f�r das Einf�gen ist garantiert logarithmisch. Wie gesagt k�nnen sich jedoch Balancefaktoren ge�ndert haben, sodass die AVL-Eigenschaft nicht mehr erf�llt ist. Das wird durch sogenannte Rotationen behoben. Es gibt zwei Typen von Rotationen -- Linksrotation und Rechtsrotation, jeweils um einen Knoten n.

\centerpic{avl/rotateleft}{5}{Linksrotation um den Knoten 65}  \medskip
\centerpic{avl/rotateright}{5}{Rechtsrotation um den Knoten 58}  \medskip

Falls durch das Einf�gen irgendwo ein Balancefaktor $2$($-2$) entsteht (gr��ere �nderungen k�nnen beim Einf�gen eines Knotens offensichtlich nicht auftreten), hei�t das, dass sich im rechten (linken) Teilbaum die H�he um 1 erh�ht hat. Durch Rotation(en) wie im Algorithmus angegeben, wird aber genau diese H�he wieder reduziert. Somit ist klar, dass man maximal zweimal rotieren muss, der Aufwand ist also noch ertr�glich, im Gegensatz zum L�schen, wie man gleich sehen wird.

Genauso wie Einf�gen ver�ndert auch L�schen eines Knotens aus einem AVL-Baum die Balancefaktoren, also m�ssen auch hier Rotationen ausgef�hrt werden. Hier der Algorithmus:

\begin{alg} \label{avldelete}
	L�schen eines Knotens aus einem AVL-Baum)
	\begin{enumerate}
		\item L�sche den Knoten analog zum L�schen im Suchbaum (Algorithmus \ref{delete}). Falls der Knoten ein Blatt war oder nur einen linken Nachbarn hatte, setze aktuellen Knoten auf den Vater. Sonst setze aktuellen Knoten auf den Vater des Knotens mit dem n�chst gr��eren Schl�ssel.
		\item Berechne den Balancefaktor des aktuellen Knotens neu. Falls
			\begin{enumerate}
				\item Balance 2 und rechte Balance -1, dann Rechts(n.right)-Links(n)-Rotation.
				\item Balance 2 und rechte Balance nicht -1, dann Links(n)-Rotation.
				\item Balance -2 und linke Balance 1, dann Links(n.left)-Rechts(n)-Rotation.
				\item Balance -2 und linke Balance nicht 1, dann Rechts(n)-Rotation.
				\item sonst keine Rotation.
			\end{enumerate}
			Wiederhole diesen Schritt solange, bis die Wurzel erreicht ist.
	\end{enumerate}
\end{alg}

Auch hier wollen wir den Aufwand des Algorithmus etwas genauer untersuchen. Schritt 1 entspricht dem L�schen aus dem Suchbaum, nur garantiert mit logarithmischen Aufwand. Die Frage ist nun, ob, wie beim Einf�gen, der Algorithmus mit maximal zwei Rotationen auskommt. Leider ist das nicht der Fall. Das liegt an der erw�hnten Eigenschaft der Rotationen, sie verringern die H�he eines Teilbaums. Beim Einf�gen war das gut, da durch das Anh�ngen eines Knotens gerade die H�he vergr��ert wurde. Hier jedoch ist das unvorteilhaft, es kann passieren, dass man mehrere Rotationen auf dem Weg zur Wurzel durchf�hren muss. Die Anzahl der Rotationen ist nur durch die H�he des Baums beschr�nkt. Das ist in Anwendungsf�llen nicht w�nschenswert.

Bei zeitkritischen Anwendungen muss man also entweder auf einen anderen Algorithmus ausweichen, oder Varianten wie etwa Lazy-Delete implementieren, d.h. der Knoten wird nur als gel�scht markiert und wird sp�ter (wenn Zeit ist) aus dem Baum entfernt.

\begin{thebibliography}{99}
    \bibitem {sedgewick} R. Sedgewick, "`Algorithmen in C++"', Addison-Wesley, 5. Auflage, 1999
    \bibitem {vogler} Prof. Vogler, "`Vorlesungsskript Algorithmen, Datenstrukturen und Programmierung"', TU Dresden, 2003
    \bibitem {wiki} http://de.wikipedia.org/wiki/AVL-Baum
    \bibitem {uni-leipzig} http://dbs.uni-leipzig.de/de/skripte/ADS1/HTML/kap6-11.html
\end{thebibliography}